{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"/home/user/elwakeely1/Cuda_Vision_Lab-/mast3r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/home/nfs/inf6/data/datasets/ThermalDBs/Freiburg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20854\n"
     ]
    }
   ],
   "source": [
    "# Initialize dataset\n",
    "train_dataset = Dataset.Freiburg_dataset(root_dir=\"/home/nfs/inf6/data/datasets/ThermalDBs/Freiburg\",split=\"train\")\n",
    "print(len(train_dataset))\n",
    "\n",
    "\n",
    "# # Get images from dataset\n",
    "# img_ir_aligned, img_rgb, img_rgb_labels = train_dataset.__getitem__(6)\n",
    "\n",
    "# # Create a figure with 3 subplots\n",
    "# fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# # Display each image\n",
    "# axes[0].imshow(img_ir_aligned, cmap=\"gray\")  # Thermal Image\n",
    "# axes[0].set_title(\"IR Aligned\")\n",
    "# axes[0].axis(\"off\")\n",
    "\n",
    "# axes[1].imshow(img_rgb)  # RGB Image\n",
    "# axes[1].set_title(\"RGB\")\n",
    "# axes[1].axis(\"off\")\n",
    "\n",
    "# axes[2].imshow(img_rgb_labels)  # Labels Image\n",
    "# axes[2].set_title(\"RGB Labels\")\n",
    "# axes[2].axis(\"off\")\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning, cannot find cuda-compiled version of RoPE2D, using a slow pytorch version instead\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "from mast3r.model import AsymmetricMASt3R\n",
    "from mast3r.fast_nn import fast_reciprocal_NNs\n",
    "from dust3r.inference import inference\n",
    "from dust3r.utils.image import load_images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.PngImagePlugin.PngImageFile image mode=I size=1920x650 at 0x7F85B31AB5B0>\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=I size=1920x650 at 0x7F8563D89A60>\n",
      ">> Loading a list of 2 images\n",
      " - adding /home/nfs/inf6/data/datasets/ThermalDBs/Freiburg/train/seq_00_day/00/fl_rgb/fl_rgb_1570722156_952177040.png with resolution 1920x650 --> 512x160\n",
      " - adding /home/nfs/inf6/data/datasets/ThermalDBs/Freiburg/train/seq_00_day/00/fl_rgb/fl_rgb_1570722157_2840648400.png with resolution 1920x650 --> 512x160\n",
      " (Found 2 images)\n",
      "pred1 keys: dict_keys(['conf', 'desc', 'desc_conf', 'pts3d_in_other_view'])\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "model_name = \"naver/MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric\"\n",
    "\n",
    "# Load pre-trained MASt3R model\n",
    "model = AsymmetricMASt3R.from_pretrained(model_name).to(device)\n",
    "\n",
    "# Process consecutive frames\n",
    "for i_1 in range(len(train_dataset) - 1):  # Process (I_t, I_t+1)\n",
    "    img1_path, img2_path = str(train_dataset[i_1]), str(train_dataset[i_1 + 1])\n",
    "\n",
    "    # Load and preprocess images\n",
    "    images = load_images([img1_path, img2_path], size=512)\n",
    "    output = inference([tuple(images)], model, device, batch_size=1, verbose=False)\n",
    "\n",
    "    # Get predictions (depth, pose, intrinsics, descriptors)\n",
    "    view1, pred1 = output['view1'], output['pred1']\n",
    "    view2, pred2 = output['view2'], output['pred2']\n",
    "    print(\"pred1 keys:\", pred2.keys())\n",
    "    # print(\"view1 keys:\", view1.keys())\n",
    "    # # depth is third Z-coordinates of pts3d -> represents the 3d coordinates  \n",
    "    pts3d1 = pred1['pts3d'].squeeze(0).detach()\n",
    "    pts3d2 = pred2['pts3d_in_other_view'].squeeze(0).detach()\n",
    "    # pts3d1,pts3d2 = pred1['pts3d'].squeeze(0).detach() ,pred2['pts3d'].squeeze(0).detach()\n",
    "    \n",
    "    desc1, desc2 = pred1['desc'].squeeze(0).detach(), pred2['desc'].squeeze(0).detach()\n",
    "    \n",
    "    # find 2D-2D matches between the two images\n",
    "    matches_im0, matches_im1 = fast_reciprocal_NNs(desc1, desc2, subsample_or_initxy1=8,\n",
    "                                            device=device, dist='dot', block_size=2**13)\n",
    "\n",
    "    # ignore small border around the edge\n",
    "    H0, W0 = view1['true_shape'][0]\n",
    "    valid_matches_im0 = (matches_im0[:, 0] >= 3) & (matches_im0[:, 0] < int(W0) - 3) & (\n",
    "        matches_im0[:, 1] >= 3) & (matches_im0[:, 1] < int(H0) - 3)\n",
    "\n",
    "    H1, W1 = view2['true_shape'][0]\n",
    "    valid_matches_im1 = (matches_im1[:, 0] >= 3) & (matches_im1[:, 0] < int(W1) - 3) & (\n",
    "        matches_im1[:, 1] >= 3) & (matches_im1[:, 1] < int(H1) - 3)\n",
    "\n",
    "    valid_matches = valid_matches_im0 & valid_matches_im1\n",
    "    matches_im0, matches_im1 = matches_im0[valid_matches], matches_im1[valid_matches]\n",
    "    #  Depth of the first image is the z coordinate of the pointmap\n",
    "    # image tensors (and depth maps) follow (height, width, channels)\n",
    "    # Extract pixel coordinates (i, j)\n",
    "    i_1 = torch.tensor(matches_im0[:, 1])  # x-coordinates (width)\n",
    "    j_1 = torch.tensor(matches_im0[:, 0])  # y-coordinates (height)\n",
    "\n",
    "    i_2 = torch.tensor(matches_im1[:, 1])  # x-coordinates (width)\n",
    "    j_2 = torch.tensor(matches_im1[:, 0])  # y-coordinates (height)\n",
    "\n",
    "    X_n = pts3d1[i_1, j_1, :]\n",
    "    X_m = pts3d2[i_2,j_2,:]\n",
    "    \n",
    "    # Depth\n",
    "    D =pts3d1[i_1, j_1, 2] \n",
    "    \n",
    "    # Intrinsics \n",
    "    # Compute pixel-coordinate matrix\n",
    "    pixel_coords = torch.stack([i_1 * D, j_1 * D, D], dim=1)  \n",
    "    \n",
    "    # Solve for K using least squares\n",
    "    K, _, _, _ = torch.linalg.lstsq(X_n, pixel_coords)\n",
    "    \n",
    "    # Pose\n",
    "    # Convert X^n to homogeneous coordinates\n",
    "    ones = torch.ones(X_n.shape[0], 1)\n",
    "    X_n_h = torch.cat([X_n, ones], dim=1)  # Shape: (N, 4)\n",
    "    \n",
    "    # Solve for P_n using least squares\n",
    "    P_n, _, _, _ = torch.linalg.lstsq(X_m, X_n_h)  # (3, 4)\n",
    "    P_n = P_n.T\n",
    "    print(P_n.shape)\n",
    "\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mast3r_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
