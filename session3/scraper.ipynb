{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import io\n",
    "import os\n",
    "import time \n",
    "from PIL import Image\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from urllib.parse import quote_plus  \n",
    "from tqdm import tqdm  \n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_google_images_url(query):\n",
    "    # Encode the query to ensure it's URL-safe\n",
    "    encoded_query = quote_plus(query)\n",
    "    return f\"https://www.google.com/search?hl=en&tbm=isch&q={encoded_query}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imgs_from_google(driver, max_num_imgs, url):\n",
    "    driver.get(url)\n",
    "    img_urls = set()\n",
    "    try:\n",
    "        driver.find_element(By.ID, 'W0wltc').click()\n",
    "    except Exception as e:\n",
    "        print(\"Error clicking consent button:\", e)\n",
    "\n",
    "    # Set up the progress bar with max_num_imgs as the total number of iterations\n",
    "    with tqdm(total=max_num_imgs, desc=\"Collecting Images\") as pbar:\n",
    "        while len(img_urls) < max_num_imgs:\n",
    "            imgs = driver.find_elements(By.CLASS_NAME, \"mNsIhb\")\n",
    "            for i, img in enumerate(imgs[len(img_urls):], start=len(img_urls)):\n",
    "                actions = ActionChains(driver)\n",
    "                actions.move_to_element(img).perform()\n",
    "                time.sleep(2)  # Wait for overlay elements to load\n",
    "                driver.execute_script(\"arguments[0].click();\", img)\n",
    "                try:\n",
    "                    images = WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.CSS_SELECTOR, \".sFlh5c.FyHeAf.iPVvYb\"))\n",
    "                    )\n",
    "                    img_url = images.get_attribute(\"src\")\n",
    "                    if img_url not in img_urls:  # Avoid duplicates\n",
    "                        img_urls.add(img_url)\n",
    "                        pbar.update(1)  # Update the progress bar\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "                if len(img_urls) >= max_num_imgs:\n",
    "                    break\n",
    "\n",
    "    driver.quit()\n",
    "    return img_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(download_path, urls, prefix):\n",
    "    if not os.path.exists(download_path):\n",
    "        os.makedirs(download_path)  # Create the directory if it doesn't exist\n",
    "    \n",
    "    # Use tqdm for a progress bar over the range of URLs\n",
    "    for i, url in enumerate(tqdm(urls, desc=\"Downloading Images\", unit=\"image\")):\n",
    "        try:\n",
    "            image_content = requests.get(url).content\n",
    "            image_file = io.BytesIO(image_content)\n",
    "            image = Image.open(image_file)\n",
    "            \n",
    "            # File path with prefix and image number\n",
    "            file_path = os.path.join(download_path, f\"{prefix}_{i + 1}.jpg\")\n",
    "            \n",
    "            # Convert image to RGB if it's in RGBA or P mode\n",
    "            if image.mode in (\"RGBA\", \"P\"):\n",
    "                image = image.convert(\"RGB\")\n",
    "            \n",
    "            # Save the image as JPEG\n",
    "            with open(file_path, \"wb\") as f:\n",
    "                image.save(f, \"JPEG\")\n",
    "            # print(f\"{i + 1} --> done\")  # Progress message\n",
    "\n",
    "        except (requests.exceptions.RequestException, IOError) as e:\n",
    "        # ``Log and continue on errors without breaking the loop\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting Images: 100%|██████████| 300/300 [17:15<00:00,  3.45s/it]\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()  \n",
    "search =\"robots pictures\"\n",
    "url_robots = get_google_images_url(search)\n",
    "urls_robots = get_imgs_from_google(driver,300,url_robots)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URLs saved to urls_robots.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save the URLs array to a file using pickle\n",
    "with open(\"urls_robots.pkl\", \"wb\") as file:\n",
    "    pickle.dump(urls_robots, file)\n",
    "    print(\"URLs saved to urls_robots.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting Images: 100%|██████████| 300/300 [24:25<00:00,  4.88s/it]\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()  \n",
    "search =\"people photography\"\n",
    "url_humans = get_google_images_url(search)\n",
    "urls_humans = get_imgs_from_google(driver,300,url_humans)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URLs saved to urls_humans.pkl\n"
     ]
    }
   ],
   "source": [
    "with open(\"urls_humans.pkl\", \"wb\") as file:\n",
    "    pickle.dump(urls_humans, file)\n",
    "    print(\"URLs saved to urls_humans.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URLs loaded from urls_robots.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load the URLs array from the pickle file\n",
    "with open(\"urls_robots.pkl\", \"rb\") as file:\n",
    "    urls_robots = pickle.load(file)\n",
    "    print(\"URLs loaded from urls_robots.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URLs loaded from urls_humans.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load the URLs array from the pickle file\n",
    "with open(\"urls_humans.pkl\", \"rb\") as file:\n",
    "    urls_robots = pickle.load(file)\n",
    "    print(\"URLs loaded from urls_humans.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Images: 100%|██████████| 300/300 [02:11<00:00,  2.27image/s]\n"
     ]
    }
   ],
   "source": [
    "# download_image(\"images//Robots\",urls_robots,\"robot\")\n",
    "download_image(\"images//Humans\",urls_humans,\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Images:  43%|████▎     | 129/300 [00:49<02:02,  1.40image/s]C:\\Users\\yarae\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\PIL\\Image.py:981: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "Downloading Images: 100%|██████████| 300/300 [02:12<00:00,  2.27image/s]\n"
     ]
    }
   ],
   "source": [
    "download_image(\"images//Robots\",urls_robots,\"robot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
